# The main entry point of your workflow.
# After configuring, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.
import pandas as pd
from pathlib import Path


configfile: "config/config.yaml"

params_df = pd.read_csv("config/params.tsv",sep="\t",comment='#')


def get_wildcards(params, wildcards=None):
    if wildcards is None:
        wildcards = params.columns.tolist()
    wildcards_dict = {}
    for w in wildcards:
        wildcards_dict[w] = params[w].tolist()
    return wildcards_dict


tmpdir = config['processed_data'] + '/tmp'
model_pattern = config['models'] + '/{method}/{source}'
feature_pattern = config['processed_data'] + '/features/{method}/{source}'
prediction_pattern = config['evaluation'] + '/predictions/{method}--{source}'

include: "rules/benchmark.smk"


rule all:
    input:
        unpack(lambda x: config['dependency_graph']),
        rules.all_benchmark.input

# The first rule should define the default target files
# Subsequent target rules can be specified below. They should start with all_*.


rule dependency:
    output:
        rulegraph=config['dependency_graph']['rulegraph'],
        dag=config['dependency_graph']['dag']
    shell:
        """
        snakemake --rulegraph | \
          sed -ne '/digraph snakemake_dag/,/}}/p' | 
          dot -Tsvg -Grankdir=TB > {output.rulegraph}
        snakemake --dag | \
          sed -ne '/digraph snakemake_dag/,/}}/p' | 
          dot -Tsvg -Grankdir=TB > {output.dag}
        """


rule test_GPU:
    conda:
        'envs/DeepCirCode_py3.yaml'
    resources:
        gpu=1
    script: '../test_gpu.py'

