loss	accuracy	precision	recall	dataset	epoch
0.38443028926849365	0.8137790560722351	0.8137790560722351	0.8137790560722351	train	0
0.12889501452445984	0.9534977078437805	0.9534977078437805	0.9534977078437805	train	1
0.0827736109495163	0.9707216024398804	0.9707216024398804	0.9707216024398804	train	2
0.06799935549497604	0.9772043824195862	0.9772043824195862	0.9772043824195862	train	3
0.0561869777739048	0.9815050363540649	0.9815050363540649	0.9815050363540649	train	4
0.050320129841566086	0.9834328889846802	0.9834328889846802	0.9834328889846802	train	5
0.04597589746117592	0.984555721282959	0.984555721282959	0.984555721282959	train	6
0.042167339473962784	0.9856997728347778	0.9856997728347778	0.9856997728347778	train	7
0.03965049237012863	0.9872462749481201	0.9872462749481201	0.9872462749481201	train	8
0.03622278943657875	0.9879665970802307	0.9879665970802307	0.9879665970802307	train	9
0.11482703685760498	0.9781374335289001	0.9781374335289001	0.9781374335289001	validation	0
0.049101728945970535	0.9906787276268005	0.9906787276268005	0.9906787276268005	validation	1
0.03180764243006706	0.992373526096344	0.992373526096344	0.992373526096344	validation	2
0.024510877206921577	0.9941530227661133	0.9941530227661133	0.9941530227661133	validation	3
0.021248362958431244	0.9944072365760803	0.9944072365760803	0.9944072365760803	validation	4
0.018869325518608093	0.995254635810852	0.995254635810852	0.995254635810852	validation	5
0.018896229565143585	0.995000422000885	0.995000422000885	0.995000422000885	validation	6
0.016477402299642563	0.9955088496208191	0.9955088496208191	0.9955088496208191	validation	7
0.016408579424023628	0.9956783056259155	0.9956783056259155	0.9956783056259155	validation	8
0.015891652554273605	0.9953393936157227	0.9953393936157227	0.9953393936157227	validation	9
