epoch	loss	acc	pre	f1	mcc	sen	spe	dataset
1	0.4033535420894623	0.8295980969074747	0.21739130434782608	0.014482259232440262	0.010249399697514839	0.00749063670411985	0.994588093806374	train
2	0.23154929280281067	0.8967071491173156	0.8236040609137056	0.61139896373057	0.5821039323576465	0.4861423220973783	0.9791040288634997	train
3	0.19373926520347595	0.9283836233880055	0.840321141837645	0.767100977198697	0.7290301893503986	0.7056179775280899	0.9730907997594709	train
4	0.1758098304271698	0.9345185927131588	0.8406040268456376	0.7930352196280175	0.755997686686515	0.750561797752809	0.9714371617558629	train
5	0.17009852826595306	0.9362714410917742	0.8379705400981997	0.8009385999217833	0.7641474678977455	0.7670411985018727	0.9702345159350572	train
6	0.16264836490154266	0.9372730687366971	0.8357487922705314	0.8055878928987196	0.7689614001135195	0.7775280898876404	0.9693325315694528	train
7	0.16002583503723145	0.936897458369851	0.8305489260143198	0.8055555555555556	0.7684294826645441	0.7820224719101123	0.9679795550210463	train
8	0.15691711008548737	0.9380242894703894	0.8343949044585988	0.8089540717869549	0.7725194559826534	0.7850187265917603	0.9687312086590499	train
9	0.15469510853290558	0.9381494929260048	0.8361310951239008	0.8089713843774168	0.7726994278451423	0.7835205992509363	0.969182200841852	train
10	0.1492520570755005	0.9421560035056967	0.8423529411764706	0.8229885057471266	0.788737616235649	0.8044943820224719	0.969783523752255	train
11	0.14462123811244965	0.9445348691623889	0.8539682539682539	0.8292870905587668	0.7966828360324241	0.8059925093632959	0.9723391461214672	train
12	0.14532500505447388	0.9414047827720045	0.84	0.8206896551724138	0.7859890442245396	0.802247191011236	0.9693325315694528	train
13	0.14593221247196198	0.9424064104169275	0.8453038674033149	0.8232129131437355	0.7892253273564007	0.802247191011236	0.9705351773902585	train
14	0.13924826681613922	0.9467885313634656	0.8611111111111112	0.836223506743738	0.8049682355430832	0.8127340823970037	0.9736921226698737	train
15	0.13814271986484528	0.9454112933516965	0.8487199379363848	0.833841463414634	0.8013705958685373	0.8194756554307117	0.9706855081178593	train
16	0.1371362805366516	0.9456617002629273	0.8550039401103231	0.8333333333333333	0.8012648846101211	0.8127340823970037	0.9723391461214672	train
17	0.13637864589691162	0.9464129209966196	0.8590657165479019	0.8352578906851424	0.8037298082398125	0.8127340823970037	0.9732411304870715	train
1	0.26761820912361145	0.8421664626682986	0.9488188976377953	0.15746488075792223	0.25886030822588035	0.08585678660491627	0.9990393852065321	validation
2	0.2133738249540329	0.9194614443084456	0.7820658342792282	0.7585321100917432	0.7107190369094241	0.7363733523334521	0.9574373753048104	validation
3	0.1897674798965454	0.9260709914320685	0.8860453887011106	0.7523575235752357	0.7214104342477093	0.6537228357677235	0.9825611468262765	validation
4	0.17787033319473267	0.9305691554467564	0.8469197261978842	0.7825586966938187	0.7445755189720311	0.7272889205557534	0.9727333185546442	validation
5	0.1766563057899475	0.9326805385556916	0.8644321093082835	0.7863662847154789	0.7511125382807795	0.7212326327039544	0.9765388310056898	validation
6	0.17434869706630707	0.930875152998776	0.7953865117098081	0.7999645798282122	0.7582031134250936	0.8045956537228358	0.9570679080765536	validation
7	0.20091813802719116	0.9217870257037943	0.8866970156803238	0.7328595317725752	0.7031790532623635	0.6245101531884574	0.9834478681740929	validation
8	0.17332877218723297	0.9303243574051407	0.7978932333511873	0.7969683459652253	0.7549154086331317	0.7960456002850018	0.9581763097613242	validation
9	0.18314850330352783	0.9231640146878825	0.7382158759404268	0.7929413704955883	0.7491913289556559	0.8564303526897044	0.9370058375822065	validation
10	0.17122535407543182	0.9310893512851898	0.8228966577026507	0.7918669131238446	0.7514136150763945	0.7630922693266833	0.9659351215547181	validation
11	0.17337189614772797	0.9308445532435741	0.8322107765451664	0.7880322641155505	0.7483590265495694	0.748307801923762	0.9687061257666445	validation
12	0.17694902420043945	0.9310587515299877	0.8561135833863106	0.7819607084099487	0.7453252570286596	0.7196294976843606	0.9749131752013597	validation
13	0.17849363386631012	0.9294981640146879	0.8265588003157064	0.7843100542969482	0.743692027210455	0.7461702885643036	0.9675238306362226	validation
14	0.17564095556735992	0.9309363525091799	0.8573557589951033	0.7811075550383086	0.7446427257571141	0.7173138582116139	0.9752456957067908	validation
15	0.1762174814939499	0.9273867809057528	0.8158253751705321	0.7791530944625407	0.736874658404073	0.7456359102244389	0.9650853469297274	validation
16	0.17660072445869446	0.9277539779681763	0.8150300213054426	0.7809223346014661	0.7386851891304347	0.7495546847167794	0.9647158797014704	validation
17	0.178376704454422	0.9253059975520196	0.7751951431049436	0.7854820282977415	0.7403676206123511	0.7960456002850018	0.9521170472179118	validation
