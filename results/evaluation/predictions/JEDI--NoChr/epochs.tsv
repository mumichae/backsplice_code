epoch	loss	acc	pre	f1	mcc	sen	spe	dataset
1	0.37293246388435364	0.8486199037731071	0.8524892440073756	0.6498770059739957	0.586935289177828	0.5250804467158812	0.9668095699073433	train
2	0.24860529601573944	0.9038743985819194	0.8428195260279522	0.8142857142857143	0.7503238841521285	0.7876206700738216	0.9463421380168718	train
3	0.23486849665641785	0.9039756900481134	0.8473846153846154	0.8133490844654461	0.7499461395848381	0.7819420783645656	0.9485548333563822	train
4	0.2307051122188568	0.9050898961762471	0.8509367922585959	0.8151873767258382	0.7526908312497158	0.7823206511451827	0.9499377679435763	train
5	0.22906440496444702	0.9070144340339327	0.8539741219963032	0.8191489361702127	0.7578492658880882	0.787052810902896	0.9508366754252524	train
6	0.2297874093055725	0.905849582172702	0.8516844700082169	0.8168653334646834	0.7547873459453739	0.7847813742191937	0.9500760614022957	train
7	0.2283584624528885	0.90554570777412	0.8500614502253175	0.8165272995573045	0.7541266073628617	0.7855385197804278	0.9493845941086987	train
8	0.2300625592470169	0.9070144340339327	0.8528147389969294	0.8194335169158143	0.7580003875266761	0.7885671020253644	0.9502835015903748	train
9	0.22680705785751343	0.9067612053684477	0.853678586107686	0.8186028180116267	0.757157597612523	0.786295665341662	0.9507675286958926	train
10	0.22802045941352844	0.9059002279057989	0.849561134925495	0.8175211156943626	0.7552216417253796	0.7878099564641302	0.9490388604619001	train
11	0.22647354006767273	0.9067105596353507	0.8519124565350787	0.8189146677152968	0.7572435016559598	0.7883778156350558	0.9499377679435763	train
12	0.22776192426681519	0.9060015193719929	0.8511990161918426	0.8173587876402283	0.7552909274661456	0.7861063789513534	0.9497994744848569	train
13	0.22591137886047363	0.9082299316282603	0.8558540086118516	0.8216535433070866	0.761107745709887	0.7900813931478327	0.95138984926013	train
14	0.2282426655292511	0.9065079767029628	0.8525128205128205	0.8182713132506398	0.756578984889395	0.786674238122279	0.9502835015903748	train
15	0.2270272970199585	0.9074702456318056	0.853518821603928	0.8203716448726772	0.7592219306216945	0.7897028203672156	0.9504909417784538	train
16	0.22710278630256653	0.9069131425677387	0.8501727993494613	0.8198392472064301	0.7580677818318224	0.7915956842703009	0.9490388604619001	train
17	0.2256646305322647	0.9067105596353507	0.8523448699569937	0.8188077906747984	0.7571858158078496	0.7878099564641302	0.9501452081316554	train
18	0.22538408637046814	0.9082805773613573	0.8545751633986928	0.8220846841536497	0.7614178139190203	0.7919742570509181	0.9507675286958926	train
19	0.2252446413040161	0.9071157255001266	0.8515800203873598	0.8199842952493129	0.7584586306810353	0.7906492523187583	0.9496611810261375	train
20	0.225895956158638	0.9088376804254241	0.8540353730433015	0.8235640070574397	0.763093589283381	0.7951921256861632	0.9503526483197344	train
21	0.2261921912431717	0.9082299316282603	0.856146111225118	0.8215833005120127	0.7610709450740012	0.7897028203672156	0.9515281427188494	train
22	0.22612732648849487	0.9064573309698658	0.8496133496133497	0.81886829459645	0.7568272402152068	0.7902706795381412	0.9489005670031807	train
23	0.22503602504730225	0.9083312230944542	0.8556215441327053	0.82195553806807	0.76142849941652	0.7908385387090668	0.9512515558014106	train
24	0.2251530885696411	0.9073183084325146	0.8532842234499693	0.8200589970501475	0.7588147914833315	0.7893242475865985	0.9504217950490942	train
25	0.2261500507593155	0.9070650797670297	0.8512632436837816	0.8199391620056913	0.7583556765830719	0.7908385387090668	0.9495228875674181	train
1	0.25288864970207214	0.9019042551875178	0.822717376198638	0.8175290001841281	0.7504821276545466	0.8124056539042129	0.9350893856643713	validation
2	0.24257944524288177	0.9030178547123819	0.855282493032683	0.8115684200403885	0.7482750076424326	0.7721055761401583	0.9515587367278402	validation
3	0.23630942404270172	0.9027085215110309	0.9010888252148997	0.7999796494619826	0.7449330545094435	0.7192717624994283	0.9707249228264188	validation
4	0.22781920433044434	0.9043665474702731	0.8797699666774159	0.8090048681641832	0.7500799453876141	0.7487763597273683	0.9620577360154686	validation
5	0.2261137217283249	0.9047624939680026	0.848009828009828	0.8176541659756934	0.7542013437342279	0.789396642422579	0.9475389260151295	validation
6	0.22519947588443756	0.9045274007349757	0.8481760448973563	0.8170436761986057	0.7535017734062779	0.7881158226979552	0.9476915770548526	validation
7	0.22980941832065582	0.904849107264381	0.8764277745311587	0.8109822043063611	0.751614794443824	0.7546315356113626	0.9605481868448726	validation
8	0.22874735295772552	0.902485801606058	0.8237310114857355	0.81863162497411	0.751978483228649	0.8135949865056493	0.9354455714237253	validation
9	0.2256832718849182	0.9044902807508135	0.8403773948204486	0.818951565615105	0.7545972974944145	0.7985910983029139	0.9437565724753214	validation
10	0.22779786586761475	0.9054430270109751	0.8616777738210307	0.8159352569969651	0.7544802404563961	0.7748044462741869	0.9538824247769598	validation
11	0.2260463535785675	0.9043789207983272	0.8431505851502938	0.8179676826682998	0.7538234791699895	0.7942454599515119	0.9452152379660097	validation
12	0.22681961953639984	0.9033395612417872	0.8344840721870387	0.81774065605898	0.7522862284183038	0.8016559169296922	0.9410427762135758	validation
13	0.22684501111507416	0.9053811603707049	0.8614954221770091	0.8158281351605211	0.7543235734884172	0.7747587027125932	0.9538145798704162	validation
14	0.22620254755020142	0.9042428141897326	0.8450112381510798	0.8171616226049567	0.7531434737372132	0.7910891542015461	0.9461989891108925	validation
15	0.23681162297725677	0.9047253739838405	0.8881640260950606	0.807989626452546	0.7507192854743738	0.7410914413796258	0.965399097662743	validation
16	0.231303408741951	0.9043541741422191	0.8453829984846263	0.8173354128266931	0.7534089222126279	0.7910891542015461	0.9463516401506157	validation
17	0.226040780544281	0.9043912941263812	0.8571356377602587	0.8144733366947585	0.7519798116356784	0.7758565481908422	0.9520506123002815	validation
18	0.22557248175144196	0.9043294274861109	0.8402774432830789	0.8185913378067665	0.7541472132874617	0.7979964320021957	0.9437565724753214	validation
19	0.22861778736114502	0.9047006273277324	0.8758693920891957	0.8107430705720465	0.751234197562751	0.7546315356113626	0.9603446521252417	validation
20	0.22610004246234894	0.9053316670584888	0.863278453829635	0.8152780125063377	0.7540055963050203	0.7723342939481268	0.9546456799755758	validation
21	0.23072132468223572	0.902745641495193	0.828061296218192	0.8180555555555555	0.7518071632665282	0.8082887333607794	0.9377692594728451	validation
22	0.22544361650943756	0.9051831871218402	0.8527979326110725	0.8174737393706977	0.754760693854827	0.7849595169479896	0.9497608467044336	validation
23	0.22558651864528656	0.9051831871218402	0.8683200166026772	0.8137109517442568	0.7531334378589183	0.7655642468322583	0.9569524067980596	validation
24	0.22513194382190704	0.9043418008141649	0.8408433037437283	0.8184742539153302	0.7540888221410974	0.7972645350166964	0.9440449133281319	validation
25	0.22892585396766663	0.9042551875177867	0.8580700775822727	0.8139098648453658	0.7514890613270712	0.7740725492886876	0.952525526646087	validation
