epoch	loss	acc	pre	f1	mcc	sen	spe	dataset
1	0.40335357189178467	0.8295980969074747	0.21739130434782608	0.014482259232440262	0.010249399697514839	0.00749063670411985	0.994588093806374	train
2	0.23154927790164948	0.8967071491173156	0.8236040609137056	0.61139896373057	0.5821039323576465	0.4861423220973783	0.9791040288634997	train
3	0.19373923540115356	0.9283836233880055	0.840321141837645	0.767100977198697	0.7290301893503986	0.7056179775280899	0.9730907997594709	train
4	0.17580977082252502	0.9345185927131588	0.8406040268456376	0.7930352196280175	0.755997686686515	0.750561797752809	0.9714371617558629	train
5	0.17009848356246948	0.9362714410917742	0.8379705400981997	0.8009385999217833	0.7641474678977455	0.7670411985018727	0.9702345159350572	train
6	0.1626490354537964	0.9372730687366971	0.8357487922705314	0.8055878928987196	0.7689614001135195	0.7775280898876404	0.9693325315694528	train
7	0.1600259244441986	0.936897458369851	0.8305489260143198	0.8055555555555556	0.7684294826645441	0.7820224719101123	0.9679795550210463	train
8	0.15656378865242004	0.9386503067484663	0.8377298161470823	0.8105181747873164	0.7745460040413936	0.7850187265917603	0.9694828622970535	train
9	0.15506099164485931	0.9392763240265432	0.8378378378378378	0.8129579637485538	0.7772390490179109	0.7895131086142322	0.9693325315694528	train
10	0.14905685186386108	0.942907224239389	0.8409619860356866	0.826219512195122	0.7922490614537171	0.8119850187265918	0.969182200841852	train
11	0.14609159529209137	0.9435332415174659	0.8485804416403786	0.8267383787936996	0.7934104695561051	0.8059925093632959	0.9711365003006615	train
12	0.1470472663640976	0.9436584449730813	0.8454332552693209	0.8279816513761468	0.7945532088452328	0.8112359550561797	0.9702345159350572	train
13	0.1451357901096344	0.9435332415174659	0.8502377179080824	0.8263380824027724	0.7931020899863069	0.80374531835206	0.9715874924834637	train
14	0.13775965571403503	0.945912107174158	0.856353591160221	0.8339738662567256	0.8020847663667307	0.8127340823970037	0.9726398075766687	train
15	0.1366521418094635	0.9470389382746964	0.8551401869158879	0.838487972508591	0.807047720380214	0.8224719101123595	0.9720384846662657	train
16	0.13561475276947021	0.947915362464004	0.8667198723064645	0.839258114374034	0.8087962168098256	0.8134831460674158	0.9748947684906795	train
17	0.131883442401886	0.9461625140853888	0.8588421887390959	0.8343605546995377	0.8027143757269863	0.8112359550561797	0.9732411304870715	train
1	0.26761820912361145	0.8421664626682986	0.9488188976377953	0.15746488075792223	0.25886030822588035	0.08585678660491627	0.9990393852065321	validation
2	0.2133738398551941	0.9194614443084456	0.7820658342792282	0.7585321100917432	0.7107190369094241	0.7363733523334521	0.9574373753048104	validation
3	0.18976746499538422	0.9260709914320685	0.8860453887011106	0.7523575235752357	0.7214104342477093	0.6537228357677235	0.9825611468262765	validation
4	0.17787033319473267	0.9305691554467564	0.8469197261978842	0.7825586966938187	0.7445755189720311	0.7272889205557534	0.9727333185546442	validation
5	0.17665648460388184	0.9326805385556916	0.8644321093082835	0.7863662847154789	0.7511125382807795	0.7212326327039544	0.9765388310056898	validation
6	0.17434820532798767	0.930875152998776	0.7953865117098081	0.7999645798282122	0.7582031134250936	0.8045956537228358	0.9570679080765536	validation
7	0.20094169676303864	0.9219094247246022	0.8866161616161616	0.7334447461875915	0.7037062785446074	0.6254007837548985	0.9834109214512673	validation
8	0.17239978909492493	0.9304467564259485	0.7999640869096786	0.7967450594652598	0.7547996999933673	0.7935518346989668	0.9588413507721865	validation
9	0.1863815188407898	0.9203794369645043	0.726058240768538	0.7880417073965462	0.7435693665232862	0.8615960099750624	0.9325722308431242	validation
10	0.17494721710681915	0.929406364749082	0.8268432496540818	0.7838470907898434	0.7432330663773391	0.7451015318845743	0.9676346708046997	validation
11	0.1761433482170105	0.9309669522643819	0.8420945395273024	0.7855920927580309	0.7470619056964883	0.7361952262201639	0.9713662898100939	validation
12	0.1813885122537613	0.9305691554467564	0.860219685548137	0.7787852198498587	0.7427263664346602	0.711435696473103	0.9760215768861302	validation
13	0.1794501394033432	0.9287943696450428	0.8278475962497507	0.7810294532793827	0.7403644541328752	0.7392233701460634	0.9681149782014336	validation
14	0.17735505104064941	0.930140758873929	0.8493811621564925	0.7800789904633464	0.7423740154642751	0.7212326327039544	0.9734722530111579	validation
15	0.17557260394096375	0.926499388004896	0.8111197210383573	0.7770972531551597	0.734110247803366	0.7458140363377271	0.9639769452449568	validation
16	0.1781880259513855	0.9273561811505507	0.82130107100357	0.7772147147147147	0.7354793206125578	0.7376202351264696	0.9667110027340575	validation
17	0.17947085201740265	0.9247552019583843	0.7782677720938437	0.7820615084640611	0.7366034016798487	0.785892411827574	0.9535579694081135	validation
