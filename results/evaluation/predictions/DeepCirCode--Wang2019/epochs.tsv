loss	accuracy	precision	recall	dataset	epoch
0.5634641647338867	0.7164144515991211	0.7164144515991211	0.7164144515991211	train	0
0.2752896249294281	0.8932742476463318	0.8932742476463318	0.8932742476463318	train	1
0.18438956141471863	0.9266440272331238	0.9266440272331238	0.9266440272331238	train	2
0.1456998735666275	0.9456878304481506	0.9456878304481506	0.9456878304481506	train	3
0.1105586439371109	0.9605891704559326	0.9605891704559326	0.9605891704559326	train	4
0.09018038958311081	0.966917872428894	0.966917872428894	0.966917872428894	train	5
0.07341762632131577	0.9743973016738892	0.9743973016738892	0.9743973016738892	train	6
0.06421271711587906	0.977964460849762	0.977964460849762	0.977964460849762	train	7
0.057563766837120056	0.9788274765014648	0.9788274765014648	0.9788274765014648	train	8
0.04912826791405678	0.9834302067756653	0.9834302067756653	0.9834302067756653	train	9
0.04721450060606003	0.9836603403091431	0.9836603403091431	0.9836603403091431	train	10
0.044230829924345016	0.9840055108070374	0.9840055108070374	0.9840055108070374	train	11
0.041407886892557144	0.9865370392799377	0.9865370392799377	0.9865370392799377	train	12
0.037052325904369354	0.9872274398803711	0.9872274398803711	0.9872274398803711	train	13
0.03573082759976387	0.9880329370498657	0.9880329370498657	0.9880329370498657	train	14
0.03322581201791763	0.9884932041168213	0.9884932041168213	0.9884932041168213	train	15
0.033142223954200745	0.9880329370498657	0.9880329370498657	0.9880329370498657	train	16
0.38494038581848145	0.905430257320404	0.905430257320404	0.905430257320404	validation	0
0.16126976907253265	0.9618039727210999	0.9618039727210999	0.9618039727210999	validation	1
0.09911412745714188	0.9857339859008789	0.9857339859008789	0.9857339859008789	validation	2
0.07226160913705826	0.9866544008255005	0.9866544008255005	0.9866544008255005	validation	3
0.042949166148900986	0.993787407875061	0.993787407875061	0.993787407875061	validation	4
0.03189816698431969	0.9953980445861816	0.9953980445861816	0.9953980445861816	validation	5
0.025339756160974503	0.9963184595108032	0.9963184595108032	0.9963184595108032	validation	6
0.021398650482296944	0.9963184595108032	0.9963184595108032	0.9963184595108032	validation	7
0.01565510407090187	0.997008740901947	0.997008740901947	0.997008740901947	validation	8
0.013997367583215237	0.9976990222930908	0.9976990222930908	0.9976990222930908	validation	9
0.011303371749818325	0.9986194372177124	0.9986194372177124	0.9986194372177124	validation	10
0.010696268640458584	0.9981592297554016	0.9981592297554016	0.9981592297554016	validation	11
0.010950584895908833	0.9981592297554016	0.9981592297554016	0.9981592297554016	validation	12
0.009737175889313221	0.9979291558265686	0.9979291558265686	0.9979291558265686	validation	13
0.008575436659157276	0.9986194372177124	0.9986194372177124	0.9986194372177124	validation	14
0.008412267081439495	0.9983893036842346	0.9983893036842346	0.9983893036842346	validation	15
0.008425365202128887	0.9981592297554016	0.9981592297554016	0.9981592297554016	validation	16
